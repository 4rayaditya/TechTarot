# Copy to .env and set one of the provider options below.
# Option A: OpenAI (if you have a key)
OPENAI_API_KEY=sk-REPLACE_ME
OPENAI_MODEL=gpt-4o-mini

# Option B: Hugging Face Inference (requires HF token and a model name)
# HF_API_TOKEN=hf_...
# HF_MODEL=google/flan-t5-large

# Option C: Local text-generation endpoint (self-hosted free model)
# TEXT_GEN_URL=http://localhost:7860/api/generate
# If using a local server, optionally set TEXT_GEN_TYPE to help parsing:
# TEXT_GEN_TYPE=textgen-webui
# TEXT_GEN_TYPE=oobabooga
# TEXT_GEN_TYPE=text-generation-inference

# If you don't want to call an external LLM, enable mock mode for demos:
ENABLE_MOCK=true

PORT=3000
